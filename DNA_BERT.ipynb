{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fec846-9e06-49bc-ba70-00c57c1dfdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 11:30:38.420525: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 11:31:25.524945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19470 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#from keras.models import Sequential, Model\n",
    "#from keras.layers import Dense, Input\n",
    "import datatable as dt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "PATH='/home/jm/SNUH/methylation/v2/compare/'\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # 0, 1, 2, 3 중 하나\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4 # GPU 점유 비율\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d3238-21d6-41c4-9a5d-76be7c43d021",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc089b3f-21e5-415f-9d54-b1679484e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/school/bioinfo1/35L33G.csv')\n",
    "data['labels']='binding_Motif'\n",
    "data1=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/school/bioinfo1/control.csv')\n",
    "\n",
    "data1.columns=['results','labels']\n",
    "data1['labels']='control'\n",
    "data=pd.concat([data,data1])\n",
    "df=data.drop_duplicates('results')\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edca572-963e-47e7-8700-0321915b34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0057fbf8-3da1-4214-b5e3-887312f793f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161e193d-065d-48e7-bb2e-15f023ce6313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285de65c6e3141ff9a4928986052b998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76da9ac09678488e9569b349191561fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c5c644312148bc84325375b1fe73db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_name = \"InstaDeepAI/nucleotide-transformer-500m-human-ref\"\n",
    "#model_name = \"BMILab/TCR-BERT-MLM\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb03c0b4-2a43-4ea7-93af-275c9d553cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(4, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64 * (sequence_length - 4), 128)  # Adjust input size of fc1 layer\n",
    "        self.fc2 = nn.Linear(128, 2)  # Assuming 2 classes for prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c71d4-c2d0-45a2-b172-1b7a43f06801",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3843cf-d659-4b04-9bc6-71f9760512fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = df.loc[:,'results']\n",
    "train_sequences = [''.join(list(word)) for word in data]\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(list(df['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "281980ab-e835-4a83-b1da-e69afea6bdc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        GTGGGTAAGAGCACCCGA\n",
       "1        CTTCTGGAGTGTCTGAAG\n",
       "2        CATAATTTGTGGTAGTGG\n",
       "3        CTCTTCTGGAGTGTCTGA\n",
       "4        CTTCTGGTGTGTCTGAAG\n",
       "                ...        \n",
       "24563    AAAGATGAGGTCTGTTTG\n",
       "24564    ACCCAGAAGACTGTGGAT\n",
       "24565    ATTCTCACGGAGGAAGGA\n",
       "24566    AGGCACACGCGGCACACA\n",
       "24567    GCACACGCGGCACACACG\n",
       "Name: results, Length: 24568, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816f0219-017a-4f26-8c4d-e8ac8c05296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_matrices = tokenizer(train_sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "input_ids = encoded_matrices['input_ids'].to(device)\n",
    "attention_mask = encoded_matrices['attention_mask'].to(device)\n",
    "#label_batch1 = torch.tensor(train_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8903f422-9ec8-4e45-98c7-787e9130d8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f8c79ccc884730abd11cfddfcff5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384c2715fe9143bdb671d777eeaac1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at InstaDeepAI/nucleotide-transformer-500m-human-ref were not used when initializing EsmModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-500m-human-ref and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "a=list()\n",
    "for i in range(0,input_ids.shape[0]):\n",
    "    \n",
    "    outputs = bert_model(input_ids[i:i+1],attention_mask[i:i+1])\n",
    "    a.append(outputs.last_hidden_state[:, 0, :].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "89008e3f-0172-44dd-96e8-9bc2066c37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'a' is the NumPy array you want to save\n",
    "a=np.array(a).reshape(24568, 6, 128)\n",
    "np.save('/workspace//jaeminjeon_950515/SNUH/school/bioinfo1/BERT_encoded.npy', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf56088-470f-4508-8c2e-12cd379567cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=np.array(a).reshape(24568, 10, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a84defb-01fb-4bf1-a908-a8c1a264bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24568, 1, 1280)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0248507c-56f3-466c-a326-d7739c400b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(a).reshape(24568, 35, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2433eaa-01c4-4f87-9c29-4c0c85c76e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define the CNN model\n",
    "class MLPClassifier(nn.Module):\n",
    "        def __init__(self, hidden_dim=128, n_classes=2,seed=1234):\n",
    "            super().__init__()\n",
    "            torch.manual_seed(seed)\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.n_classes = n_classes\n",
    "    \n",
    "            self.fc1 = nn.Linear(1280, self.hidden_dim)\n",
    "            self.fc2 = nn.Linear(self.hidden_dim, self.n_classes)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = nn.functional.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        #self.conv1 = nn.Conv1d(6, 32, kernel_size=3)\n",
    "        #self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        #self.fc1 = nn.Linear(7936, 128)  # Adjust input size of fc1 layer\n",
    "        #self.fc2 = nn.Linear(128, 2)  # Assuming 2 classes for prediction\n",
    "        self.conv1 = nn.Conv1d(10, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(48896, 128)  # Adjust input size of fc1 layer\n",
    "        self.fc2 = nn.Linear(128, 2)  # Assuming 2 classes for prediction\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Convert the list of matrices to a numpy array\n",
    "encoded_matrices = np.array(encoded_matrices)\n",
    "\n",
    "labels = np.array(df['labels'].tolist())\n",
    "\n",
    "# Encode labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "#a=np.array(a).reshape(24568, 6, 128)\n",
    "a=np.array(a).reshape(24568, 10, 128)\n",
    "#a=np.array(a).reshape(24568, 35, 768)\n",
    "data_train, data_val, labels_train, labels_val = train_test_split(a, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "887c9ee6-2dab-4c5f-9d6a-6a08ce87a685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24568, 1280, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc95ade-7f5e-4694-a3f4-308290ce06db",
   "metadata": {},
   "source": [
    "# MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3afa430e-bf4b-4094-a1c8-2b92acba945d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(6644.8799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(720.4700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(7454.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4465.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(28.2486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(122.4262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(281.0775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(309.9739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(277.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(266.6916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(254.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(149.9673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(69.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(58.7893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(27.5291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(131.8982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(10.8012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(215.1191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2\n",
      "tensor(0.2967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3\n",
      "tensor(0.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6\n",
      "tensor(0.2274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7\n",
      "tensor(0.2760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2739, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MLPClassifier(nn.Module):\n",
    "        #def __init__(self, hidden_dim=128, n_classes=2,seed=1234):\n",
    "        def __init__(self):\n",
    "            super(MLPClassifier, self).__init__()\n",
    "            #torch.manual_seed(seed)\n",
    "            self.hidden_dim = 640\n",
    "            self.n_classes =2\n",
    "    \n",
    "            self.fc1 = nn.Linear(1280, self.hidden_dim)\n",
    "            self.fc2 = nn.Linear(self.hidden_dim, self.n_classes)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = nn.functional.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(10, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(7936, 16)  # Adjust input size of fc1 layer\n",
    "        self.fc2 = nn.Linear(16, 2)  # Assuming 2 classes for prediction\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Convert the list of matrices to a numpy array\n",
    "encoded_matrices = np.array(encoded_matrices)\n",
    "\n",
    "labels = np.array(df['labels'].tolist())\n",
    "\n",
    "# Encode labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "#a=np.array(a).reshape(24568, 6, 128)\n",
    "a=np.array(a).reshape(24568, 1280)\n",
    "#a=np.array(a).reshape(24568, 35, 768)\n",
    "data_train, data_val, labels_train, labels_val = train_test_split(a, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = CustomDataset(data_train, labels_train)\n",
    "val_dataset = CustomDataset(data_val, labels_val)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 300\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Instantiate the CNN model\n",
    "#sequence_length = encoded_matrices.shape[1]  # Get sequence length\n",
    "sequence_length=12\n",
    "#model = CNNModel()\n",
    "model=MLPClassifier()\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.8)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for data, labels in train_loader:\n",
    "        #print(data.shape)\n",
    "        #data = data.float().permute(0, 1, 2).to(device)  # Permute dimensions for proper input shape\n",
    "        data = data.float().to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c13258a1-c40f-4553-b8ea-4dfda6559325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18279\n",
       "1     1375\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(labels_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b7bd53a-4c1a-4e5d-9dc3-686f00c16bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for data, _ in val_loader:\n",
    "        #data = data.float().permute(0, 1, 2).to(device)\n",
    "        data = data.float().to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9c674e0-e381-499c-bce8-35359232c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, \\\n",
    "    classification_report, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbece148-7f07-41ec-be34-22c6df7e6ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "binding_Motif     1.0000    0.9300    0.9637      4914\n",
      "      control     0.0000    0.0000    0.0000         0\n",
      "\n",
      "     accuracy                         0.9300      4914\n",
      "    macro avg     0.5000    0.4650    0.4819      4914\n",
      " weighted avg     1.0000    0.9300    0.9637      4914\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_encoder.inverse_transform(predictions),\n",
    "                                    label_encoder.inverse_transform(labels_val), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ac3d8-5e93-4bb5-83e0-dc7898c1c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "model.eval()\n",
    "predictions = []\n",
    "predictions_prob = []\n",
    "with torch.no_grad():\n",
    "    for data, _ in val_loader:\n",
    "        data = data.float().permute(0, 1, 2).to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prob=softmax(outputs.data, dim=1)\n",
    "        predictions_prob.extend(prob.cpu().numpy())\n",
    "        predictions.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175f0ac-007e-4fb5-8258-b1bab074a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(predictions_prob)[:,1]).to_csv('/workspace/jaeminjeon_950515/SNUH/school/bioinfo1/DNA_BERT_prob_hidden1-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c7b78-6399-46f8-aa92-3f66bde11b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(predictions_prob)[:,0]).to_csv('/workspace/jaeminjeon_950515/SNUH/school/bioinfo1/DNA_BERT_prob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e6e79-fd9b-4c7c-b5c2-9301ada25403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b57ddc-a998-4d4d-8972-7b6fabb8b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array(a).reshape(24568, 6, 128)\n",
    "#a=np.array(a).reshape(24568, 35, 768)\n",
    "data_train, data_val, labels_train, labels_val = train_test_split(a, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec9e3f-48ea-4f13-8642-154be84e532f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637929c-c3d8-4e49-9b82-b1048995737a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
